{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "feature_detection_for_students.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9ZLrWZRGDzX"
      },
      "source": [
        "# TP 2 : Computer Vision\n",
        "\n",
        "## Part 2 : feature detection\n",
        "\n",
        "In this part of the TP, we are going to look at the following feature detector :\n",
        "\n",
        "- Harris corner detection\n",
        "\n",
        "First, let us again load some packages and define some helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPBpZuBqGDzd"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np \n",
        "import imageio\n",
        "from skimage import color\n",
        "from scipy import signal\n",
        "from scipy.ndimage.morphology import binary_dilation\n",
        "\n",
        "is_colab = True\n",
        "\n",
        "def read_image(file_name):\n",
        "    img_color = imageio.imread(file_name)\n",
        "    img_gray = color.rgb2gray(img_color)\n",
        "    return img_gray,img_color\n",
        "    \n",
        "def write_image(img_in,file_name_out):\n",
        "    imageio.imwrite(file_name_out, np.uint8(255.0*img_in))\n",
        "    \n",
        "def display_image(img_in):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    if (img_in.ndim == 2):\n",
        "        plt.imshow(img_in,cmap='gray')\n",
        "    elif (img_in.ndim == 3):\n",
        "        # careful, in this case we supppose the pixel values are between 0 and 255\n",
        "        plt.imshow(np.uint8(img_in))\n",
        "    else:\n",
        "        print('Error, unknown number of dimensions in image')\n",
        "    return\n",
        "\n",
        "# this function annotates an image with coloured squares at the positions detected by the harris detector\n",
        "def annotate_image(img_in, img_harris):\n",
        "    \n",
        "    img_harris_out = np.tile( np.expand_dims(img_in,axis=2), (1,1,3))\n",
        "    block_size = 5\n",
        "    struct_el = np.ones((block_size,block_size))\n",
        "    # now annotate the image\n",
        "    img_harris = binary_dilation(img_harris,struct_el)\n",
        "    img_harris_out[img_harris>0,0] = 1.0\n",
        "    img_harris_out[img_harris>0,1:3] = 0.0\n",
        "    \n",
        "        \n",
        "    return img_harris_out\n",
        "\n",
        "\n",
        "file_dir = 'images/'\n",
        "file_name = 'mit'\n",
        "file_ext = '.png'\n",
        "\n",
        "if (is_colab == True):\n",
        "  !wget \"https://perso.telecom-paristech.fr/anewson/doc/images/mit.png\"\n",
        "  img_gray,_ = read_image(file_name+file_ext)\n",
        "else:\n",
        "  img_gray,_ = read_image(file_dir+file_name+file_ext)\n",
        "\n",
        "display_image(img_gray)\n",
        "img_gray.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzwzArDsGDzh"
      },
      "source": [
        "The goal of the Harris detector is to detect corners. The criterion used is the following : if we shift the image (spatially) in any direction, the underlying image should change values. In other words, we should be able to distinguish between the initial image and the shifted image. This is not true, for example, with constant images or edges; there is an ambiguity (see the lesson slides for more detail).\n",
        "\n",
        "This criterion is formalised by associating the following matrix with __each pixel__ $p$ in the image :\n",
        "\n",
        "$A = \n",
        "    \\begin{bmatrix}\n",
        "        \\sum_{q \\in \\Psi_p} I_x(q)^2 & \\sum_{q \\in \\Psi_p} I_x(q)I_y(q) \\\\\n",
        "        \\sum_{q \\in \\Psi_p} I_x(q)I_y(q) & \\sum_{q \\in \\Psi_p} I_y(q)^2\n",
        "    \\end{bmatrix}\n",
        "$\n",
        "\n",
        "where $I_x$ is the $x$-direction component of image gradient, and similarly for $I_y$, and $\\Psi_p$ is a small ''patch'' centred on $p$. A patch is a small image square.\n",
        "\n",
        "Each pixel, therefore, contains a descriptor. The Harris detector consists in detecting the pixels whose descriptor verifies the following criterion :\n",
        "\n",
        "$| \\text{det}(A) - \\alpha \\text{trace}(A)^2 |  >k$\n",
        "\n",
        "where det refers to the determinant of the matrix, and $k$ is a threshold. If this criterion is verified, then both the eigenvalues of the matrix are very large, which means that the two principal directions of local motion in the image lead to large changes in the image (which is what we were looking for). In fact, this does not correspond to __only__ corners, however corners do verify this criterion. \n",
        "\n",
        "For more precise details about this, again, see the slides.\n",
        "\n",
        "We are going to implement this detector now.\n",
        "\n",
        "Firstly, implement a function ``harris_feature`` which calculates the previous criterion for each pixel. You will have to implement the following steps :\n",
        "\n",
        "- calculate the necessar gradients (you can use the ``np.gradient`` function) \n",
        "- create a filter to calculate the sum of the different gradients in a patch region. You should calculate these sums __before__ carrying out the two loops over the pixels, to avoid inefficient computation\n",
        "- for each pixel, create the matrix $A$ and determine the Harris feature. For the matrix operations, you can use the ``np.linalg`` subpackage\n",
        "- threshold the resulting image\n",
        "\n",
        "\n",
        "Use the following parameters :\n",
        "\n",
        "- patch_size = 7\n",
        "- $\\alpha$ = 0.04\n",
        "- $k$ = 0.048"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "xnGWRZy6GDzj"
      },
      "source": [
        "def harris_feature(img,k,alpha):\n",
        "    \n",
        "    # FILL IN HERE\n",
        "    return img_harris_detect\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqQPatMQGDzl"
      },
      "source": [
        "Now, display the resulting image. You can use the function ``annotate_image``. Note, this outputs and RGB image, where the detected points are annotated as blocks of a certain size (5 here), in red. To display this image, you need to put the pixel values back to the range $0, \\dots, 255$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8peR0r-GDzl"
      },
      "source": [
        "alpha = 0.04\n",
        "k = 0.048\n",
        "img_harris = ... # FILL IN HERE\n",
        "\n",
        "display_image(255.0*annotate_image(img_gray,img_harris))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoJb0LBiGDzm"
      },
      "source": [
        "Now, you should observe something here: regions with many detections. Therefore, there is a second step : non-maximum suppression. This simply corresponds to removing detected pixels for which the Harris feature is not the maximum in a certain region.\n",
        "\n",
        "Copy and paste the ``harris_feature`` code, and include non-maximum suppression before the output. For this, the following function can be useful:\n",
        "\n",
        "- scipy.ndimage.maximum_filter()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "H7SK_PkRGDzn"
      },
      "source": [
        "\n",
        "def harris_feature(img,k,alpha):\n",
        "    # FILL IN HERE\n",
        "    return img_harris_detect\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJitRj1gGDzo"
      },
      "source": [
        "Carry out the algorithm and display the result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BmD6Pu1GDzp"
      },
      "source": [
        "alpha = 0.04\n",
        "k = 0.048\n",
        "img_harris = harris_feature(img_gray,k,alpha)\n",
        "display_image(255.0*annotate_image(img_gray,img_harris))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52KefgzUGDzq"
      },
      "source": [
        "__Question 2.1__ Are there any corners missed ? Why do you think this is ? What solution could you propose (which we have seen in the first lesson) to improve the result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Qa5hxPrGDzq"
      },
      "source": [
        "__Answer__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "2rlmlivCGDzr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}